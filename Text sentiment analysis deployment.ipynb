{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57f2648a",
   "metadata": {},
   "source": [
    "# Text sentiment analysis deployment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8739aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import pandas as pd\n",
    "# Loading the vectoriser\n",
    "file = open('vectoriser.pickle', 'rb')\n",
    "vectoriser = pickle.load(file)\n",
    "file.close()\n",
    "# Loading the LR Model\n",
    "file = open('Sentiment.pickle', 'rb')\n",
    "LRmodel = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86875b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis = {':)': 'smile', ':-)': 'smile', ';d': 'wink', ':-E': 'vampire', ':(': 'sad', \n",
    "          ':-(': 'sad', ':-<': 'sad', ':P': 'raspberry', ':O': 'surprised',\n",
    "          ':-@': 'shocked', ':@': 'shocked',':-$': 'confused', ':\\\\': 'annoyed', \n",
    "          ':#': 'mute', ':X': 'mute', ':^)': 'smile', ':-&': 'confused', '$_$': 'greedy',\n",
    "          '@@': 'eyeroll', ':-!': 'confused', ':-D': 'smile', ':-0': 'yell', 'O.o': 'confused',\n",
    "          '<(-_-)>': 'robot', 'd[-_-]b': 'dj', \":'-)\": 'sadsmile', ';)': 'wink', \n",
    "          ';-)': 'wink', 'O:-)': 'angel','O*-)': 'angel','(:-D': 'gossip', '=^.^=': 'cat'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1967899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(textdata):\n",
    "    processedText = []\n",
    "    \n",
    "    # Creating Lemmatizer and Stemmer.\n",
    "    wordLemm = WordNetLemmatizer() #converting words to their base or dictionary form\n",
    "    \n",
    "    # Defining regex patterns.\n",
    "    urlPattern        = r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\" #to match URLs in the text\n",
    "    userPattern       = '@[^\\s]+' #to identify and potentially remove user mentions from the text\n",
    "    alphaPattern      = \"[^a-zA-Z0-9]\" #to remove non-alphanumeric characters from the text.\n",
    "    sequencePattern   = r\"(.)\\1\\1+\" #to identify sequences of repeated characters (3 or more repetitions) in the text\n",
    "    seqReplacePattern = r\"\\1\\1\" #to replace sequences of repeated characters with just two occurrences of the same character.\n",
    "    \n",
    "    for tweet in textdata:\n",
    "        tweet = tweet.lower()\n",
    "        tweet = re.sub(urlPattern,' URL',tweet)\n",
    "        for emoji in emojis.keys():\n",
    "            tweet = tweet.replace(emoji, \"EMOJI\" + emojis[emoji])        \n",
    "        tweet = re.sub(userPattern,' USER', tweet)\n",
    "        \n",
    "        tweet = re.sub(alphaPattern, \" \", tweet)\n",
    "        tweet = re.sub(sequencePattern, seqReplacePattern, tweet)\n",
    "\n",
    "        tweetwords = ''\n",
    "        for word in tweet.split():\n",
    "            if len(word)>1:\n",
    "                word = wordLemm.lemmatize(word)\n",
    "                tweetwords += (word+' ')\n",
    "            \n",
    "        processedText.append(tweetwords)\n",
    "        \n",
    "    return processedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a756c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a tweet:I hate twitter\n",
      "\n",
      "\n",
      "             text sentiment\n",
      "0  I hate twitter  Negative\n"
     ]
    }
   ],
   "source": [
    "text =input('Enter a tweet:')\n",
    "text=[text]\n",
    "print()\n",
    "print()\n",
    "# Predict the sentiment\n",
    "textdata = vectoriser.transform(preprocess(text))\n",
    "sentiment = LRmodel.predict(textdata)\n",
    "    \n",
    "# Make a list of text with sentiment.\n",
    "data = []\n",
    "for text, pred in zip(text, sentiment):\n",
    "    data.append((text,pred))\n",
    "        \n",
    "# Convert the list into a Pandas DataFrame.\n",
    "df = pd.DataFrame(data, columns = ['text','sentiment'])\n",
    "df = df.replace([0,1], [\"Negative\",\"Positive\"])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5133d68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc8d965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
